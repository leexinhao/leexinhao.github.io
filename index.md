---
layout: page
---

<!-- > Nice to meet you !!!üòä Hope you are happy every day!!!üí• -->

## Biography

<img src="images/big_xinhao.jpg" style="float: right;" width="327" height="279">

> Nice to meet you !!!üòä

I am a MS student üôÇ at **Nanjing University** (2023.09‚Äî2026.06 if everything goes as expected), supervised by Prof. [*<font color="#006ab1">Limin Wang</font>*](https://scholar.google.com.hk/citations?user=HEuN8PcAAAAJ&hl=zh-CN&oi=ao). Previously, I received a bachelor degree from **Chongqing University** in 2023.06 (Major in computer science and technology üñ•Ô∏è, GPA: 3.9/4.0 overall rank: 1/295). I am also working as a research intern in [<font color="#006ab1">Shanghai AI lab</font>](https://www.shlab.org.cn/) (2023.07‚Äîpresent). Before that, I worked as an intern in [<font color="#006ab1">SenseTime</font>](https://www.sensetime.com) (2022.10‚Äî2023.06).

<!-- ## Academic Background

**<font color='red'>[Highlight]</font> I am looking for PhD to start in 2025 Fall. Contact me if you have any leads!** [talk with me](https://calendly.com/lancecai/meet-with-lance)

- **Sep 2020 - June 2024:** Fuzhou University (BEng)
- **Sep 2020 - May 2024:** Maynooth University (BSc)
- **June 2022 - Nov 2022:** Cambridge University (Intern)

<br>

--- -->

## Research Interests

My research interests lies at the computer vision and multimodal:

- Vision-Language Representation Learning
- Vision Foundation Models
- Multimodal Instruction-following Agents
- Parameter-Efficient Transfer Learning


I am particularly interested in the progress of the above direction in the field of **video understanding**. Currently, I am researching how to build and evaluate the long video mllms.
 <!-- Additionally, I am researching how to utilize pre-trained language models for creating multimodal instruction-following agents that can understand videos excellently. -->


---

## News and Updates
- **Jul 2024:** Three papers accepted by ECCV2024.
- **Mar 2024:** We present [InternVideo2](https://arxiv.org/pdf/2403.15377.pdf), the currently largest (6B parameters) and most powerful video foundation model.
- **Mar 2024:** We present [VideoMamba](https://arxiv.org/abs/2403.06977), an efficient video backbone architecture with the potential to serve as an alternative to the video transformer architecture.
- **Jan 2024:** One paper accepted by ICLR2024 (spotlight).
- **Dec 2023:** Accepted by üêº.
- **June 2023** Happy to graduate from Chongqing University. Thank you to all my classmates and teachers.

<br>
